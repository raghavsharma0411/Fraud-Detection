{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "main_title"
      },
      "source": [
        "# üîç **Complete Guide to Credit Card Fraud Detection with Machine Learning**\n",
        "\n",
        "---\n",
        "\n",
        "## üìã **Table of Contents**\n",
        "1. [Introduction & Overview](#introduction)\n",
        "2. [Data Loading & Initial Exploration](#data-loading)\n",
        "3. [Data Preprocessing & Feature Engineering](#preprocessing)\n",
        "4. [Exploratory Data Analysis (EDA)](#eda)\n",
        "5. [Model Training & Evaluation](#training)\n",
        "6. [Model Comparison & Selection](#comparison)\n",
        "7. [Model Deployment Preparation](#deployment)\n",
        "8. [Key Insights & Recommendations](#insights)\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ **Learning Objectives**\n",
        "By the end of this notebook, you will understand:\n",
        "- How to preprocess transaction data for fraud detection\n",
        "- Feature engineering techniques for temporal data\n",
        "- Different machine learning approaches for fraud detection\n",
        "- Model evaluation metrics for imbalanced datasets\n",
        "- How to prepare models for production deployment\n",
        "\n",
        "---\n",
        "\n",
        "## üö® **Problem Statement**\n",
        "**Credit card fraud** costs billions of dollars annually. We need to build a machine learning system that can:\n",
        "- **Identify fraudulent transactions** in real-time\n",
        "- **Minimize false positives** (blocking legitimate transactions)\n",
        "- **Maximize fraud detection** while maintaining customer experience\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports_section"
      },
      "source": [
        "# üì¶ **1. Import Required Libraries**\n",
        "\n",
        "First, we'll import all the necessary libraries for our fraud detection analysis. Each library serves a specific purpose:\n",
        "\n",
        "- **pandas**: Data manipulation and analysis\n",
        "- **numpy**: Numerical computations\n",
        "- **matplotlib/seaborn**: Data visualization\n",
        "- **sklearn**: Machine learning algorithms and utilities\n",
        "- **joblib**: Model serialization for deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "# Data manipulation and analysis\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning - Model Selection\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "\n",
        "# Machine Learning - Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Machine Learning - Algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Machine Learning - Evaluation Metrics\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report, roc_auc_score,\n",
        "    roc_curve, precision_recall_curve\n",
        ")\n",
        "\n",
        "# Model serialization for deployment\n",
        "import joblib\n",
        "\n",
        "# System utilities\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Configure plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"üìä Pandas version: {pd.__version__}\")\n",
        "print(f\"ü§ñ Scikit-learn version: {sklearn.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_loading_section"
      },
      "source": [
        "# üìä **2. Data Loading & Initial Exploration**\n",
        "\n",
        "In this section, we'll load our fraud detection dataset and perform initial exploration to understand:\n",
        "- **Dataset structure** (rows, columns, data types)\n",
        "- **Feature meanings** and ranges\n",
        "- **Data quality** (missing values, duplicates)\n",
        "- **Class distribution** (fraud vs legitimate transactions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [],
      "source": [
        "# Load the fraud detection dataset\n",
        "# This dataset contains transaction features and fraud labels\n",
        "print(\"üîÑ Loading fraud detection dataset...\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(\"fraud_dataset.csv\")\n",
        "    print(f\"‚úÖ Dataset loaded successfully!\")\n",
        "    print(f\"üìè Dataset shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå Dataset file not found. Please ensure 'fraud_dataset.csv' is in the current directory.\")\n",
        "    print(\"üí° You can download sample fraud datasets from Kaggle or create synthetic data.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "initial_exploration"
      },
      "source": [
        "## üîç **Initial Dataset Exploration**\n",
        "\n",
        "Let's examine the structure and content of our dataset to understand what we're working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "explore_data"
      },
      "outputs": [],
      "source": [
        "# Display basic information about the dataset\n",
        "print(\"üìã DATASET OVERVIEW\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Rows: {df.shape[0]:,}\")\n",
        "print(f\"Columns: {df.shape[1]}\")\n",
        "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "print(\"\\nüìä COLUMN INFORMATION\")\n",
        "print(\"=\" * 50)\n",
        "df.info()\n",
        "\n",
        "print(\"\\nüéØ TARGET VARIABLE DISTRIBUTION\")\n",
        "print(\"=\" * 50)\n",
        "if 'fraud_label' in df.columns:\n",
        "    fraud_counts = df['fraud_label'].value_counts()\n",
        "    fraud_percent = df['fraud_label'].value_counts(normalize=True) * 100\n",
        "    \n",
        "    print(f\"Legitimate transactions (0): {fraud_counts[0]:,} ({fraud_percent[0]:.2f}%)\")\n",
        "    print(f\"Fraudulent transactions (1): {fraud_counts[1]:,} ({fraud_percent[1]:.2f}%)\")\n",
        "    print(f\"\\n‚ö†Ô∏è  Class imbalance ratio: {fraud_counts[0]/fraud_counts[1]:.1f}:1\")\n",
        "else:\n",
        "    print(\"Target variable 'fraud_label' not found in dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "display_sample"
      },
      "outputs": [],
      "source": [
        "# Display first few rows to understand the data structure\n",
        "print(\"üëÄ SAMPLE DATA (First 10 rows)\")\n",
        "print(\"=\" * 70)\n",
        "display(df.head(10))\n",
        "\n",
        "print(\"\\nüìà BASIC STATISTICS\")\n",
        "print(\"=\" * 50)\n",
        "display(df.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature_explanation"
      },
      "source": [
        "## üìñ **Understanding Our Features**\n",
        "\n",
        "Let's understand what each column represents in fraud detection:\n",
        "\n",
        "### **Identifier Features:**\n",
        "- `transaction_id`: Unique identifier for each transaction\n",
        "- `customer_id`: Unique identifier for each customer\n",
        "\n",
        "### **Transaction Details:**\n",
        "- `tx_datetime`: When the transaction occurred\n",
        "- `amount`: Transaction amount in currency units\n",
        "\n",
        "### **Risk Indicators (Binary Features):**\n",
        "- `is_weekend`: 1 if transaction on weekend, 0 otherwise\n",
        "- `night_transaction`: 1 if transaction during night hours (10PM-6AM)\n",
        "- `card_not_present`: 1 if online/phone transaction, 0 if physical card used\n",
        "- `new_merchant`: 1 if first transaction with this merchant\n",
        "- `international_txn`: 1 if transaction in foreign country\n",
        "- `impossible_travel`: 1 if location change physically impossible\n",
        "- `new_device_high_amount`: 1 if high amount from new device\n",
        "- `blacklisted_ip`: 1 if transaction from suspicious IP\n",
        "- `multiple_cards_same_device`: 1 if multiple cards used on same device\n",
        "\n",
        "### **Behavioral Features:**\n",
        "- `account_age_days`: How long the account has existed\n",
        "- `txn_velocity_5min`: Number of transactions in last 5 minutes\n",
        "\n",
        "### **Target Variable:**\n",
        "- `fraud_label`: 1 = Fraud, 0 = Legitimate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_data_quality"
      },
      "outputs": [],
      "source": [
        "# Check for data quality issues\n",
        "print(\"üîç DATA QUALITY CHECK\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "if missing_values.sum() > 0:\n",
        "    print(\"‚ö†Ô∏è  MISSING VALUES FOUND:\")\n",
        "    for col, count in missing_values[missing_values > 0].items():\n",
        "        print(f\"  - {col}: {count} ({count/len(df)*100:.2f}%)\")\n",
        "else:\n",
        "    print(\"‚úÖ No missing values found\")\n",
        "\n",
        "# Check for duplicate transactions\n",
        "duplicates = df.duplicated().sum()\n",
        "if duplicates > 0:\n",
        "    print(f\"\\n‚ö†Ô∏è  {duplicates} duplicate rows found\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ No duplicate rows found\")\n",
        "\n",
        "# Check for duplicate transaction IDs (should be unique)\n",
        "if 'transaction_id' in df.columns:\n",
        "    unique_txn_ids = df['transaction_id'].nunique()\n",
        "    total_rows = len(df)\n",
        "    if unique_txn_ids != total_rows:\n",
        "        print(f\"\\n‚ö†Ô∏è  Transaction ID issue: {unique_txn_ids} unique IDs for {total_rows} rows\")\n",
        "    else:\n",
        "        print(\"\\n‚úÖ All transaction IDs are unique\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "preprocessing_section"
      },
      "source": [
        "# üõ†Ô∏è **3. Data Preprocessing & Feature Engineering**\n",
        "\n",
        "Now we'll prepare our data for machine learning by:\n",
        "1. **Converting datetime** to useful temporal features\n",
        "2. **Engineering new features** from existing ones\n",
        "3. **Handling data types** properly\n",
        "4. **Preparing for model input**\n",
        "\n",
        "## üìÖ **Temporal Feature Engineering**\n",
        "Time-based features are crucial for fraud detection as fraudulent patterns often relate to timing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "datetime_processing"
      },
      "outputs": [],
      "source": [
        "# Process datetime column to extract useful temporal features\n",
        "print(\"‚è∞ PROCESSING TEMPORAL FEATURES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'tx_datetime' in df.columns:\n",
        "    # Convert to datetime if it's not already\n",
        "    df['tx_datetime'] = pd.to_datetime(df['tx_datetime'])\n",
        "    print(f\"‚úÖ Converted tx_datetime to datetime type\")\n",
        "    \n",
        "    # Extract temporal components\n",
        "    print(\"üîß Extracting temporal features...\")\n",
        "    \n",
        "    # Hour of day (0-23) - Important for fraud patterns\n",
        "    df['tx_hour'] = df['tx_datetime'].dt.hour\n",
        "    print(\"  ‚úì tx_hour: Hour of transaction (0-23)\")\n",
        "    \n",
        "    # Day of month (1-31)\n",
        "    df['tx_day'] = df['tx_datetime'].dt.day\n",
        "    print(\"  ‚úì tx_day: Day of month (1-31)\")\n",
        "    \n",
        "    # Month (1-12) - Seasonal patterns\n",
        "    df['tx_month'] = df['tx_datetime'].dt.month\n",
        "    print(\"  ‚úì tx_month: Month of year (1-12)\")\n",
        "    \n",
        "    # Day of week (0=Monday, 6=Sunday)\n",
        "    df['tx_weekday'] = df['tx_datetime'].dt.dayofweek\n",
        "    print(\"  ‚úì tx_weekday: Day of week (0=Mon, 6=Sun)\")\n",
        "    \n",
        "    # Show temporal feature statistics\n",
        "    print(\"\\nüìä TEMPORAL FEATURE DISTRIBUTION:\")\n",
        "    temporal_cols = ['tx_hour', 'tx_day', 'tx_month', 'tx_weekday']\n",
        "    for col in temporal_cols:\n",
        "        if col in df.columns:\n",
        "            print(f\"  {col}: range {df[col].min()}-{df[col].max()}, unique values: {df[col].nunique()}\")\n",
        "    \n",
        "    # We'll keep the original datetime for now, but drop it before model training\n",
        "    print(\"\\nüí° Note: We'll drop tx_datetime before model training as models need numeric features\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  tx_datetime column not found in dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_engineering"
      },
      "outputs": [],
      "source": [
        "# Additional feature engineering\n",
        "print(\"üîß ADDITIONAL FEATURE ENGINEERING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create risk score based on multiple factors\n",
        "if all(col in df.columns for col in ['night_transaction', 'international_txn', \n",
        "                                    'card_not_present', 'new_merchant']):\n",
        "    df['risk_score'] = (\n",
        "        df['night_transaction'] * 1 +           # Night transactions are riskier\n",
        "        df['international_txn'] * 2 +           # International transactions more risky\n",
        "        df['card_not_present'] * 1 +            # Online transactions riskier\n",
        "        df['new_merchant'] * 1 +                # New merchants riskier\n",
        "        df['impossible_travel'] * 3 +           # Impossible travel very risky\n",
        "        df['blacklisted_ip'] * 4 +              # Blacklisted IPs very risky\n",
        "        df['multiple_cards_same_device'] * 2    # Multiple cards suspicious\n",
        "    )\n",
        "    print(\"‚úÖ Created composite risk_score feature (0-14 scale)\")\n",
        "    print(f\"   Risk score range: {df['risk_score'].min()}-{df['risk_score'].max()}\")\n",
        "\n",
        "# Create amount category based on transaction size\n",
        "if 'amount' in df.columns:\n",
        "    # Define amount thresholds\n",
        "    amount_q25 = df['amount'].quantile(0.25)\n",
        "    amount_q75 = df['amount'].quantile(0.75)\n",
        "    \n",
        "    df['amount_category'] = pd.cut(\n",
        "        df['amount'],\n",
        "        bins=[0, amount_q25, amount_q75, df['amount'].max()],\n",
        "        labels=['low', 'medium', 'high'],\n",
        "        include_lowest=True\n",
        "    )\n",
        "    \n",
        "    # Convert to numeric for model\n",
        "    df['amount_category_num'] = df['amount_category'].map({'low': 0, 'medium': 1, 'high': 2})\n",
        "    print(f\"‚úÖ Created amount_category feature based on quartiles\")\n",
        "    print(f\"   Low: ${0:.2f}-${amount_q25:.2f}\")\n",
        "    print(f\"   Medium: ${amount_q25:.2f}-${amount_q75:.2f}\")\n",
        "    print(f\"   High: ${amount_q75:.2f}-${df['amount'].max():.2f}\")\n",
        "\n",
        "# Create account maturity feature\n",
        "if 'account_age_days' in df.columns:\n",
        "    df['account_maturity'] = pd.cut(\n",
        "        df['account_age_days'],\n",
        "        bins=[0, 30, 180, 365, float('inf')],\n",
        "        labels=['new', 'young', 'mature', 'old']\n",
        "    )\n",
        "    df['account_maturity_num'] = df['account_maturity'].map({\n",
        "        'new': 0, 'young': 1, 'mature': 2, 'old': 3\n",
        "    })\n",
        "    print(\"‚úÖ Created account_maturity feature\")\n",
        "    print(\"   New: 0-30 days, Young: 31-180 days, Mature: 181-365 days, Old: 365+ days\")\n",
        "\n",
        "print(f\"\\nüìè Dataset shape after feature engineering: {df.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_preprocessing"
      },
      "outputs": [],
      "source": [
        "# Prepare dataset for machine learning\n",
        "print(\"üéØ PREPARING DATA FOR MACHINE LEARNING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Create a copy for model training\n",
        "df_model = df.copy()\n",
        "\n",
        "# Remove non-numeric columns that won't be used in model\n",
        "columns_to_drop = []\n",
        "\n",
        "# Drop datetime column (we've extracted features from it)\n",
        "if 'tx_datetime' in df_model.columns:\n",
        "    columns_to_drop.append('tx_datetime')\n",
        "\n",
        "# Drop categorical columns if we have numeric versions\n",
        "if 'amount_category' in df_model.columns:\n",
        "    columns_to_drop.append('amount_category')\n",
        "    \n",
        "if 'account_maturity' in df_model.columns:\n",
        "    columns_to_drop.append('account_maturity')\n",
        "\n",
        "# Drop columns\n",
        "df_model = df_model.drop(columns=[col for col in columns_to_drop if col in df_model.columns])\n",
        "\n",
        "print(f\"‚úÖ Dropped non-numeric columns: {columns_to_drop}\")\n",
        "\n",
        "# Show final feature list\n",
        "feature_columns = [col for col in df_model.columns if col != 'fraud_label']\n",
        "print(f\"\\nüìã FINAL FEATURES FOR MODEL ({len(feature_columns)} total):\")\n",
        "for i, col in enumerate(feature_columns, 1):\n",
        "    print(f\"  {i:2d}. {col}\")\n",
        "\n",
        "print(f\"\\nüéØ Target variable: fraud_label\")\n",
        "print(f\"üìè Final dataset shape: {df_model.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eda_section"
      },
      "source": [
        "# üìà **4. Exploratory Data Analysis (EDA)**\n",
        "\n",
        "Now let's analyze our data to understand fraud patterns and relationships between features. This helps us:\n",
        "- **Identify fraud indicators** in different features\n",
        "- **Understand data distributions** and outliers\n",
        "- **Discover feature correlations**\n",
        "- **Validate our feature engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fraud_distribution_viz"
      },
      "outputs": [],
      "source": [
        "# Visualize fraud distribution\n",
        "print(\"üìä FRAUD DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'fraud_label' in df.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "    \n",
        "    # Count plot\n",
        "    fraud_counts = df['fraud_label'].value_counts()\n",
        "    axes[0].bar(['Legitimate', 'Fraud'], fraud_counts.values, \n",
        "                color=['lightgreen', 'lightcoral'])\n",
        "    axes[0].set_title('Transaction Distribution')\n",
        "    axes[0].set_ylabel('Count')\n",
        "    \n",
        "    # Add count labels on bars\n",
        "    for i, v in enumerate(fraud_counts.values):\n",
        "        axes[0].text(i, v + max(fraud_counts.values)*0.01, f'{v:,}', \n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # Pie chart\n",
        "    axes[1].pie(fraud_counts.values, labels=['Legitimate', 'Fraud'], \n",
        "                colors=['lightgreen', 'lightcoral'], autopct='%1.2f%%')\n",
        "    axes[1].set_title('Transaction Percentage')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Class imbalance analysis\n",
        "    fraud_ratio = fraud_counts[0] / fraud_counts[1]\n",
        "    print(f\"\\n‚öñÔ∏è  CLASS IMBALANCE ANALYSIS:\")\n",
        "    print(f\"   Imbalance ratio: {fraud_ratio:.1f}:1\")\n",
        "    if fraud_ratio > 10:\n",
        "        print(\"   ‚ö†Ô∏è  High class imbalance - consider sampling techniques or adjusted metrics\")\n",
        "    else:\n",
        "        print(\"   ‚úÖ Moderate class imbalance - standard techniques should work\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amount_analysis"
      },
      "outputs": [],
      "source": [
        "# Analyze transaction amounts\n",
        "print(\"üí∞ TRANSACTION AMOUNT ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'amount' in df.columns and 'fraud_label' in df.columns:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    \n",
        "    # Amount distribution by fraud status\n",
        "    legitimate = df[df['fraud_label'] == 0]['amount']\n",
        "    fraudulent = df[df['fraud_label'] == 1]['amount']\n",
        "    \n",
        "    # Histogram\n",
        "    axes[0,0].hist([legitimate, fraudulent], bins=50, alpha=0.7, \n",
        "                   label=['Legitimate', 'Fraud'], color=['green', 'red'])\n",
        "    axes[0,0].set_title('Amount Distribution by Fraud Status')\n",
        "    axes[0,0].set_xlabel('Transaction Amount')\n",
        "    axes[0,0].set_ylabel('Frequency')\n",
        "    axes[0,0].legend()\n",
        "    \n",
        "    # Box plot\n",
        "    df.boxplot(column='amount', by='fraud_label', ax=axes[0,1])\n",
        "    axes[0,1].set_title('Amount Distribution by Fraud Status')\n",
        "    axes[0,1].set_xlabel('Fraud Label (0=Legitimate, 1=Fraud)')\n",
        "    \n",
        "    # Violin plot\n",
        "    fraud_labels = ['Legitimate', 'Fraud']\n",
        "    amount_data = [legitimate, fraudulent]\n",
        "    axes[1,0].violinplot(amount_data, positions=[0, 1])\n",
        "    axes[1,0].set_xticks([0, 1])\n",
        "    axes[1,0].set_xticklabels(fraud_labels)\n",
        "    axes[1,0].set_title('Amount Distribution Shape')\n",
        "    axes[1,0].set_ylabel('Transaction Amount')\n",
        "    \n",
        "    # Amount statistics by category\n",
        "    stats_data = df.groupby('fraud_label')['amount'].agg(['mean', 'median', 'std']).round(2)\n",
        "    stats_data.index = ['Legitimate', 'Fraud']\n",
        "    \n",
        "    # Bar plot for means\n",
        "    axes[1,1].bar(stats_data.index, stats_data['mean'], color=['green', 'red'], alpha=0.7)\n",
        "    axes[1,1].set_title('Average Transaction Amount')\n",
        "    axes[1,1].set_ylabel('Mean Amount')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print statistics\n",
        "    print(\"\\nüìä AMOUNT STATISTICS:\")\n",
        "    print(stats_data)\n",
        "    \n",
        "    # Insight\n",
        "    if stats_data.loc['Fraud', 'mean'] > stats_data.loc['Legitimate', 'mean']:\n",
        "        print(\"\\nüí° INSIGHT: Fraudulent transactions have higher average amounts\")\n",
        "    else:\n",
        "        print(\"\\nüí° INSIGHT: Legitimate transactions have higher average amounts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "temporal_analysis"
      },
      "outputs": [],
      "source": [
        "# Analyze temporal patterns\n",
        "print(\"‚è∞ TEMPORAL FRAUD PATTERNS ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "temporal_features = ['tx_hour', 'tx_weekday', 'tx_month']\n",
        "available_temporal = [col for col in temporal_features if col in df.columns]\n",
        "\n",
        "if available_temporal and 'fraud_label' in df.columns:\n",
        "    fig, axes = plt.subplots(len(available_temporal), 1, figsize=(12, 6*len(available_temporal)))\n",
        "    \n",
        "    if len(available_temporal) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, feature in enumerate(available_temporal):\n",
        "        # Calculate fraud rate by temporal feature\n",
        "        fraud_rate = df.groupby(feature)['fraud_label'].agg(['sum', 'count'])\n",
        "        fraud_rate['fraud_rate'] = fraud_rate['sum'] / fraud_rate['count']\n",
        "        \n",
        "        # Create dual y-axis plot\n",
        "        ax1 = axes[idx]\n",
        "        ax2 = ax1.twinx()\n",
        "        \n",
        "        # Bar chart for transaction count\n",
        "        ax1.bar(fraud_rate.index, fraud_rate['count'], alpha=0.6, \n",
        "                color='lightblue', label='Total Transactions')\n",
        "        ax1.set_ylabel('Transaction Count', color='blue')\n",
        "        ax1.tick_params(axis='y', labelcolor='blue')\n",
        "        \n",
        "        # Line chart for fraud rate\n",
        "        ax2.plot(fraud_rate.index, fraud_rate['fraud_rate'], \n",
        "                color='red', marker='o', linewidth=2, label='Fraud Rate')\n",
        "        ax2.set_ylabel('Fraud Rate', color='red')\n",
        "        ax2.tick_params(axis='y', labelcolor='red')\n",
        "        \n",
        "        # Formatting\n",
        "        feature_name = feature.replace('tx_', '').replace('_', ' ').title()\n",
        "        ax1.set_title(f'Transaction Volume and Fraud Rate by {feature_name}')\n",
        "        ax1.set_xlabel(feature_name)\n",
        "        \n",
        "        # Add legends\n",
        "        lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "        ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print insights\n",
        "    print(\"\\nüí° TEMPORAL INSIGHTS:\")\n",
        "    for feature in available_temporal:\n",
        "        fraud_rate = df.groupby(feature)['fraud_label'].mean()\n",
        "        highest_risk_time = fraud_rate.idxmax()\n",
        "        highest_risk_rate = fraud_rate.max()\n",
        "        print(f\"  - {feature}: Highest fraud rate at {highest_risk_time} ({highest_risk_rate:.3f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "risk_factors_analysis"
      },
      "outputs": [],
      "source": [
        "# Analyze binary risk factors\n",
        "print(\"üö® RISK FACTORS ANALYSIS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "binary_features = [\n",
        "    'is_weekend', 'night_transaction', 'card_not_present', \n",
        "    'new_merchant', 'international_txn', 'impossible_travel',\n",
        "    'new_device_high_amount', 'blacklisted_ip', 'multiple_cards_same_device'\n",
        "]\n",
        "available_binary = [col for col in binary_features if col in df.columns]\n",
        "\n",
        "if available_binary and 'fraud_label' in df.columns:\n",
        "    # Calculate fraud rates for each risk factor\n",
        "    risk_analysis = {}\n",
        "    \n",
        "    for feature in available_binary:\n",
        "        fraud_rate_0 = df[df[feature] == 0]['fraud_label'].mean()\n",
        "        fraud_rate_1 = df[df[feature] == 1]['fraud_label'].mean()\n",
        "        \n",
        "        risk_analysis[feature] = {\n",
        "            'without_factor': fraud_rate_0,\n",
        "            'with_factor': fraud_rate_1,\n",
        "            'risk_multiplier': fraud_rate_1 / fraud_rate_0 if fraud_rate_0 > 0 else float('inf')\n",
        "        }\n",
        "    \n",
        "    # Create visualization\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
        "    \n",
        "    # Fraud rate comparison\n",
        "    features = list(risk_analysis.keys())\n",
        "    without_factor = [risk_analysis[f]['without_factor'] for f in features]\n",
        "    with_factor = [risk_analysis[f]['with_factor'] for f in features]\n",
        "    \n",
        "    x = np.arange(len(features))\n",
        "    width = 0.35\n",
        "    \n",
        "    axes[0].bar(x - width/2, without_factor, width, label='Without Factor', \n",
        "                color='lightgreen', alpha=0.8)\n",
        "    axes[0].bar(x + width/2, with_factor, width, label='With Factor', \n",
        "                color='lightcoral', alpha=0.8)\n",
        "    \n",
        "    axes[0].set_ylabel('Fraud Rate')\n",
        "    axes[0].set_title('Fraud Rate: With vs Without Risk Factors')\n",
        "    axes[0].set_xticks(x)\n",
        "    axes[0].set_xticklabels([f.replace('_', '\\n') for f in features], rotation=45, ha='right')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Risk multipliers\n",
        "    risk_multipliers = [risk_analysis[f]['risk_multiplier'] for f in features]\n",
        "    bars = axes[1].bar(features, risk_multipliers, color='orange', alpha=0.7)\n",
        "    axes[1].set_ylabel('Risk Multiplier')\n",
        "    axes[1].set_title('How Much Each Factor Increases Fraud Risk')\n",
        "    axes[1].set_xticklabels([f.replace('_', '\\n') for f in features], rotation=45, ha='right')\n",
        "    axes[1].axhline(y=1, color='red', linestyle='--', alpha=0.7, label='No increase')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, value in zip(bars, risk_multipliers):\n",
        "        if value != float('inf'):\n",
        "            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
        "                        f'{value:.1f}x', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print top risk factors\n",
        "    print(\"\\nüî• TOP RISK FACTORS (sorted by risk multiplier):\")\n",
        "    sorted_factors = sorted(risk_analysis.items(), \n",
        "                          key=lambda x: x[1]['risk_multiplier'], reverse=True)\n",
        "    \n",
        "    for i, (factor, stats) in enumerate(sorted_factors[:5], 1):\n",
        "        multiplier = stats['risk_multiplier']\n",
        "        if multiplier != float('inf'):\n",
        "            print(f\"  {i}. {factor}: {multiplier:.1f}x higher fraud rate\")\n",
        "            print(f\"     Without factor: {stats['without_factor']:.3f} | With factor: {stats['with_factor']:.3f}\")\n",
        "        else:\n",
        "            print(f\"  {i}. {factor}: Only fraudulent transactions have this factor\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training_section"
      },
      "source": [
        "# ü§ñ **5. Machine Learning Model Training & Evaluation**\n",
        "\n",
        "Now we'll train different machine learning models to detect fraud. We'll use:\n",
        "1. **Logistic Regression** - Fast, interpretable baseline\n",
        "2. **Random Forest** - Ensemble method, good for imbalanced data\n",
        "3. **Decision Tree** - Simple, interpretable\n",
        "\n",
        "## üìä **Data Preparation for ML**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data_preparation"
      },
      "outputs": [],
      "source": [
        "# Prepare features and target for machine learning\n",
        "print(\"üéØ PREPARING DATA FOR MACHINE LEARNING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Separate features and target\n",
        "if 'fraud_label' in df_model.columns:\n",
        "    # Features (X) - everything except the target\n",
        "    X = df_model.drop('fraud_label', axis=1)\n",
        "    # Target (y) - what we want to predict\n",
        "    y = df_model['fraud_label']\n",
        "    \n",
        "    print(f\"‚úÖ Features (X): {X.shape}\")\n",
        "    print(f\"‚úÖ Target (y): {y.shape}\")\n",
        "    print(f\"\\nüìã FEATURE LIST ({len(X.columns)} features):\")\n",
        "    for i, col in enumerate(X.columns, 1):\n",
        "        print(f\"  {i:2d}. {col}\")\n",
        "else:\n",
        "    print(\"‚ùå fraud_label column not found!\")\n",
        "    X = df_model\n",
        "    y = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_test_split"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "print(\"‚úÇÔ∏è  SPLITTING DATA INTO TRAIN/TEST SETS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if y is not None:\n",
        "    # Split the data: 80% for training, 20% for testing\n",
        "    # stratify=y ensures both sets have similar fraud ratios\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, \n",
        "        test_size=0.2,           # 20% for testing\n",
        "        random_state=42,         # For reproducible results\n",
        "        stratify=y               # Maintain fraud ratio in both sets\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Training set: {X_train.shape[0]:,} samples\")\n",
        "    print(f\"‚úÖ Test set: {X_test.shape[0]:,} samples\")\n",
        "    \n",
        "    # Check fraud distribution in both sets\n",
        "    train_fraud_rate = y_train.mean()\n",
        "    test_fraud_rate = y_test.mean()\n",
        "    \n",
        "    print(f\"\\nüìä FRAUD DISTRIBUTION CHECK:\")\n",
        "    print(f\"  Training set fraud rate: {train_fraud_rate:.3f} ({train_fraud_rate*100:.1f}%)\")\n",
        "    print(f\"  Test set fraud rate: {test_fraud_rate:.3f} ({test_fraud_rate*100:.1f}%)\")\n",
        "    \n",
        "    if abs(train_fraud_rate - test_fraud_rate) < 0.01:\n",
        "        print(\"  ‚úÖ Good: Similar fraud rates in both sets\")\n",
        "    else:\n",
        "        print(\"  ‚ö†Ô∏è  Warning: Different fraud rates in train/test sets\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot split data - no target variable found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scaling_section"
      },
      "source": [
        "## ‚öñÔ∏è **Feature Scaling**\n",
        "\n",
        "Many ML algorithms perform better when features are on similar scales. We'll use StandardScaler to normalize our features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature_scaling"
      },
      "outputs": [],
      "source": [
        "# Scale features for better model performance\n",
        "print(\"‚öñÔ∏è  SCALING FEATURES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'X_train' in locals() and X_train is not None:\n",
        "    # Initialize the scaler\n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    # Fit scaler on training data and transform both training and test data\n",
        "    # Important: Only fit on training data to avoid data leakage\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    print(f\"‚úÖ Scaled training features: {X_train_scaled.shape}\")\n",
        "    print(f\"‚úÖ Scaled test features: {X_test_scaled.shape}\")\n",
        "    \n",
        "    # Show scaling statistics for a few features\n",
        "    print(f\"\\nüìä SCALING VERIFICATION (first 5 features):\")\n",
        "    for i in range(min(5, len(X.columns))):\n",
        "        feature_name = X.columns[i]\n",
        "        original_mean = X_train.iloc[:, i].mean()\n",
        "        original_std = X_train.iloc[:, i].std()\n",
        "        scaled_mean = X_train_scaled[:, i].mean()\n",
        "        scaled_std = X_train_scaled[:, i].std()\n",
        "        \n",
        "        print(f\"  {feature_name}:\")\n",
        "        print(f\"    Original: mean={original_mean:.2f}, std={original_std:.2f}\")\n",
        "        print(f\"    Scaled:   mean={scaled_mean:.3f}, std={scaled_std:.3f}\")\n",
        "    \n",
        "    print(\"\\nüí° Note: After scaling, features have mean‚âà0 and std‚âà1\")\n",
        "    print(\"üí° This helps algorithms like Logistic Regression converge faster\")\n",
        "else:\n",
        "    print(\"‚ùå Cannot scale features - training data not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "logistic_regression_section"
      },
      "source": [
        "## üìà **Model 1: Logistic Regression**\n",
        "\n",
        "Logistic Regression is our baseline model. It's:\n",
        "- **Fast to train** and predict\n",
        "- **Highly interpretable** - we can understand feature importance\n",
        "- **Good baseline** for binary classification problems\n",
        "- **Requires scaled features** for optimal performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "logistic_regression_training"
      },
      "outputs": [],
      "source": [
        "# Train Logistic Regression model\n",
        "print(\"üìà TRAINING LOGISTIC REGRESSION MODEL\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'X_train_scaled' in locals() and y_train is not None:\n",
        "    # Initialize and train the model\n",
        "    # class_weight='balanced' helps with imbalanced data\n",
        "    lr_model = LogisticRegression(\n",
        "        class_weight='balanced',  # Adjust for class imbalance\n",
        "        random_state=42,         # For reproducible results\n",
        "        max_iter=1000           # Increase iterations for convergence\n",
        "    )\n",
        "    \n",
        "    print(\"üîÑ Training model...\")\n",
        "    lr_model.fit(X_train_scaled, y_train)\n",
        "    print(\"‚úÖ Logistic Regression model trained!\")\n",
        "    \n",
        "    # Make predictions\n",
        "    y_train_pred_lr = lr_model.predict(X_train_scaled)\n",
        "    y_test_pred_lr = lr_model.predict(X_test_scaled)\n",
        "    y_test_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    \n",
        "    print(\"\\nüéØ LOGISTIC REGRESSION PERFORMANCE:\")\n",
        "    \n",
        "    # Training performance\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred_lr)\n",
        "    print(f\"  Training Accuracy: {train_accuracy:.4f}\")\n",
        "    \n",
        "    # Test performance\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred_lr)\n",
        "    test_precision = precision_score(y_test, y_test_pred_lr)\n",
        "    test_recall = recall_score(y_test, y_test_pred_lr)\n",
        "    test_f1 = f1_score(y_test, y_test_pred_lr)\n",
        "    test_auc = roc_auc_score(y_test, y_test_proba_lr)\n",
        "    \n",
        "    print(f\"  Test Accuracy:  {test_accuracy:.4f}\")\n",
        "    print(f\"  Test Precision: {test_precision:.4f} (Of predicted frauds, how many were correct?)\")\n",
        "    print(f\"  Test Recall:    {test_recall:.4f} (Of actual frauds, how many did we catch?)\")\n",
        "    print(f\"  Test F1-Score:  {test_f1:.4f} (Balanced precision and recall)\")\n",
        "    print(f\"  Test AUC:       {test_auc:.4f} (Area Under ROC Curve)\")\n",
        "    \n",
        "    # Feature importance\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'coefficient': lr_model.coef_[0],\n",
        "        'abs_coefficient': abs(lr_model.coef_[0])\n",
        "    }).sort_values('abs_coefficient', ascending=False)\n",
        "    \n",
        "    print(f\"\\nüîç TOP 10 MOST IMPORTANT FEATURES (by coefficient magnitude):\")\n",
        "    for i, (_, row) in enumerate(feature_importance.head(10).iterrows(), 1):\n",
        "        direction = \"‚ÜóÔ∏è\" if row['coefficient'] > 0 else \"‚ÜòÔ∏è\"\n",
        "        print(f\"  {i:2d}. {row['feature']}: {row['coefficient']:+.3f} {direction}\")\n",
        "    \n",
        "    print(\"\\nüí° Positive coefficients increase fraud probability\")\n",
        "    print(\"üí° Negative coefficients decrease fraud probability\")\n",
        "    \n",
        "    # Save Logistic Regression model and scaler\n",
        "    print(\"\\nüíæ SAVING LOGISTIC REGRESSION MODEL...\")\n",
        "    import os\n",
        "    os.makedirs('../models', exist_ok=True)\n",
        "    \n",
        "    # Save model with algorithm-specific naming\n",
        "    joblib.dump(lr_model, '../models/logistic_regression_model.pkl')\n",
        "    print(\"‚úÖ Saved: logistic_regression_model.pkl\")\n",
        "    \n",
        "    # Save scaler (shared, but we'll save algorithm-specific versions)\n",
        "    joblib.dump(scaler, '../models/logistic_regression_scaler.pkl')\n",
        "    print(\"‚úÖ Saved: logistic_regression_scaler.pkl\")\n",
        "    \n",
        "    # Save feature columns\n",
        "    joblib.dump(list(X.columns), '../models/logistic_regression_columns.pkl')\n",
        "    print(\"‚úÖ Saved: logistic_regression_columns.pkl\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot train model - scaled data not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "logistic_regression_confusion_matrix"
      },
      "outputs": [],
      "source": [
        "# Detailed evaluation with confusion matrix\n",
        "if 'y_test_pred_lr' in locals():\n",
        "    print(\"üìä DETAILED LOGISTIC REGRESSION EVALUATION\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_test_pred_lr)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=['Legitimate', 'Fraud'],\n",
        "                yticklabels=['Legitimate', 'Fraud'])\n",
        "    plt.title('Logistic Regression - Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "    \n",
        "    # Interpret confusion matrix\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    print(f\"\\nüéØ CONFUSION MATRIX BREAKDOWN:\")\n",
        "    print(f\"  True Negatives (Correct Legitimate):  {tn:,}\")\n",
        "    print(f\"  False Positives (Wrong Fraud Alert):  {fp:,}\")\n",
        "    print(f\"  False Negatives (Missed Frauds):      {fn:,}\")\n",
        "    print(f\"  True Positives (Caught Frauds):       {tp:,}\")\n",
        "    \n",
        "    # Business impact\n",
        "    print(f\"\\nüíº BUSINESS IMPACT:\")\n",
        "    print(f\"  Frauds caught: {tp:,} out of {tp+fn:,} total frauds ({tp/(tp+fn)*100:.1f}%)\")\n",
        "    print(f\"  False alarms: {fp:,} legitimate transactions blocked\")\n",
        "    print(f\"  Customer impact: {fp/(fp+tn)*100:.2f}% of legitimate customers affected\")\n",
        "    \n",
        "    # Classification report\n",
        "    print(f\"\\nüìã DETAILED CLASSIFICATION REPORT:\")\n",
        "    print(classification_report(y_test, y_test_pred_lr, \n",
        "                              target_names=['Legitimate', 'Fraud']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "random_forest_section"
      },
      "source": [
        "## üå≤ **Model 2: Random Forest**\n",
        "\n",
        "Random Forest is an ensemble method that:\n",
        "- **Combines multiple decision trees** for better performance\n",
        "- **Handles imbalanced data well** naturally\n",
        "- **Provides feature importance** rankings\n",
        "- **Resistant to overfitting** compared to single decision trees\n",
        "- **Works with unscaled features** (but we'll use scaled for consistency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "random_forest_training"
      },
      "outputs": [],
      "source": [
        "# Train Random Forest model\n",
        "print(\"üå≤ TRAINING RANDOM FOREST MODEL\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if 'X_train_scaled' in locals() and y_train is not None:\n",
        "    # Initialize Random Forest with parameters optimized for fraud detection\n",
        "    rf_model = RandomForestClassifier(\n",
        "        n_estimators=100,          # Number of trees in the forest\n",
        "        class_weight='balanced',   # Handle class imbalance\n",
        "        random_state=42,          # For reproducible results\n",
        "        max_depth=10,             # Prevent overfitting\n",
        "        min_samples_split=10,     # Minimum samples to split a node\n",
        "        min_samples_leaf=5,       # Minimum samples in leaf nodes\n",
        "        n_jobs=-1                 # Use all CPU cores for faster training\n",
        "    )\n",
        "    \n",
        "    print(\"üîÑ Training Random Forest (this may take a moment)...\")\n",
        "    rf_model.fit(X_train_scaled, y_train)\n",
        "    print(\"‚úÖ Random Forest model trained!\")\n",
        "    \n",
        "    # Make predictions\n",
        "    y_train_pred_rf = rf_model.predict(X_train_scaled)\n",
        "    y_test_pred_rf = rf_model.predict(X_test_scaled)\n",
        "    y_test_proba_rf = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    \n",
        "    print(\"\\nüéØ RANDOM FOREST PERFORMANCE:\")\n",
        "    \n",
        "    # Training performance\n",
        "    train_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\n",
        "    print(f\"  Training Accuracy: {train_accuracy_rf:.4f}\")\n",
        "    \n",
        "    # Test performance\n",
        "    test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
        "    test_precision_rf = precision_score(y_test, y_test_pred_rf)\n",
        "    test_recall_rf = recall_score(y_test, y_test_pred_rf)\n",
        "    test_f1_rf = f1_score(y_test, y_test_pred_rf)\n",
        "    test_auc_rf = roc_auc_score(y_test, y_test_proba_rf)\n",
        "    \n",
        "    print(f\"  Test Accuracy:  {test_accuracy_rf:.4f}\")\n",
        "    print(f\"  Test Precision: {test_precision_rf:.4f}\")\n",
        "    print(f\"  Test Recall:    {test_recall_rf:.4f}\")\n",
        "    print(f\"  Test F1-Score:  {test_f1_rf:.4f}\")\n",
        "    print(f\"  Test AUC:       {test_auc_rf:.4f}\")\n",
        "    \n",
        "    # Feature importance from Random Forest\n",
        "    rf_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': rf_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    print(f\"\\nüîç TOP 10 MOST IMPORTANT FEATURES (Random Forest):\")\n",
        "    for i, (_, row) in enumerate(rf_importance.head(10).iterrows(), 1):\n",
        "        print(f\"  {i:2d}. {row['feature']}: {row['importance']:.3f}\")\n",
        "    \n",
        "    # Visualize feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.barh(rf_importance.head(15)['feature'][::-1], \n",
        "             rf_importance.head(15)['importance'][::-1])\n",
        "    plt.title('Top 15 Feature Importances - Random Forest')\n",
        "    plt.xlabel('Importance Score')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Save Random Forest model and scaler\n",
        "    print(\"\\nüíæ SAVING RANDOM FOREST MODEL...\")\n",
        "    \n",
        "    # Save model with algorithm-specific naming\n",
        "    joblib.dump(rf_model, '../models/random_forest_model.pkl')\n",
        "    print(\"‚úÖ Saved: random_forest_model.pkl\")\n",
        "    \n",
        "    # Save scaler (Random Forest version)\n",
        "    joblib.dump(scaler, '../models/random_forest_scaler.pkl')\n",
        "    print(\"‚úÖ Saved: random_forest_scaler.pkl\")\n",
        "    \n",
        "    # Save feature columns (Random Forest version)\n",
        "    joblib.dump(list(X.columns), '../models/random_forest_columns.pkl')\n",
        "    print(\"‚úÖ Saved: random_forest_columns.pkl\")\n",
        "    \n",
        "    # Save feature importance for Random Forest\n",
        "    joblib.dump(rf_importance, '../models/random_forest_importance.pkl')\n",
        "    print(\"‚úÖ Saved: random_forest_importance.pkl\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot train model - scaled data not available\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_comparison_section"
      },
      "source": [
        "## ‚öñÔ∏è **6. Model Comparison & Selection**\n",
        "\n",
        "Let's compare our models to see which performs best for fraud detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_comparison"
      },
      "outputs": [],
      "source": [
        "# Compare model performances\n",
        "print(\"‚öñÔ∏è  MODEL COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if 'test_accuracy_rf' in locals() and 'test_accuracy' in locals():\n",
        "    \n",
        "    # Create comparison DataFrame\n",
        "    comparison = pd.DataFrame({\n",
        "        'Model': ['Logistic Regression', 'Random Forest'],\n",
        "        'Accuracy': [test_accuracy, test_accuracy_rf],\n",
        "        'Precision': [test_precision, test_precision_rf],\n",
        "        'Recall': [test_recall, test_recall_rf],\n",
        "        'F1-Score': [test_f1, test_f1_rf],\n",
        "        'AUC': [test_auc, test_auc_rf]\n",
        "    })\n",
        "    \n",
        "    print(\"üìä PERFORMANCE COMPARISON:\")\n",
        "    print(comparison.round(4).to_string(index=False))\n",
        "    \n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "    \n",
        "    for i, metric in enumerate(metrics):\n",
        "        row = i // 3\n",
        "        col = i % 3\n",
        "        \n",
        "        bars = axes[row, col].bar(comparison['Model'], comparison[metric], \n",
        "                                  color=['lightblue', 'lightgreen'], alpha=0.8)\n",
        "        axes[row, col].set_title(f'{metric} Comparison')\n",
        "        axes[row, col].set_ylim(0, 1)\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for bar, value in zip(bars, comparison[metric]):\n",
        "            axes[row, col].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                               f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # Remove empty subplot\n",
        "    fig.delaxes(axes[1, 2])\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # ROC Curve Comparison\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    \n",
        "    # Logistic Regression ROC\n",
        "    fpr_lr, tpr_lr, _ = roc_curve(y_test, y_test_proba_lr)\n",
        "    plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {test_auc:.3f})', \n",
        "             linewidth=2, color='blue')\n",
        "    \n",
        "    # Random Forest ROC\n",
        "    fpr_rf, tpr_rf, _ = roc_curve(y_test, y_test_proba_rf)\n",
        "    plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {test_auc_rf:.3f})', \n",
        "             linewidth=2, color='green')\n",
        "    \n",
        "    # Random baseline\n",
        "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Baseline')\n",
        "    \n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curves - Model Comparison')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "    \n",
        "    # Determine best model\n",
        "    best_model_idx = comparison['F1-Score'].idxmax()\n",
        "    best_model_name = comparison.iloc[best_model_idx]['Model']\n",
        "    best_f1 = comparison.iloc[best_model_idx]['F1-Score']\n",
        "    \n",
        "    print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
        "    print(f\"   F1-Score: {best_f1:.4f}\")\n",
        "    print(f\"\\nüí° F1-Score is used as the primary metric because it balances\")\n",
        "    print(f\"   precision (avoiding false positives) and recall (catching frauds)\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå Cannot compare models - not all models were trained\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deployment_section"
      },
      "source": [
        "## üöÄ **7. Model Deployment Preparation**\n",
        "\n",
        "Now we'll prepare our best model for deployment by saving all necessary components:\n",
        "1. **Trained model** (the algorithm with learned parameters)\n",
        "2. **Scaler** (to normalize new data the same way)\n",
        "3. **Feature columns** (to ensure correct feature order)\n",
        "\n",
        "These files will be used by our FastAPI application!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_deployment_prep"
      },
      "outputs": [],
      "source": [
        "# Prepare model for deployment\n",
        "print(\"üöÄ PREPARING MODEL FOR DEPLOYMENT\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Determine which model to deploy (based on F1-score or user preference)\n",
        "if 'best_model_name' in locals():\n",
        "    if best_model_name == 'Random Forest':\n",
        "        deploy_model = rf_model\n",
        "        model_name = \"Random Forest\"\n",
        "    else:\n",
        "        deploy_model = lr_model\n",
        "        model_name = \"Logistic Regression\"\n",
        "else:\n",
        "    # Default to Random Forest if comparison wasn't done\n",
        "    if 'rf_model' in locals():\n",
        "        deploy_model = rf_model\n",
        "        model_name = \"Random Forest\"\n",
        "    elif 'lr_model' in locals():\n",
        "        deploy_model = lr_model\n",
        "        model_name = \"Logistic Regression\"\n",
        "    else:\n",
        "        print(\"‚ùå No trained models available for deployment\")\n",
        "        deploy_model = None\n",
        "\n",
        "if deploy_model is not None:\n",
        "    print(f\"üì¶ Preparing {model_name} for deployment...\")\n",
        "    \n",
        "    # Create models directory if it doesn't exist\n",
        "    import os\n",
        "    os.makedirs('../models', exist_ok=True)\n",
        "    \n",
        "    # 1. Save the trained model\n",
        "    model_path = '../models/fraud_model.pkl'\n",
        "    joblib.dump(deploy_model, model_path)\n",
        "    print(f\"‚úÖ Saved trained model: {model_path}\")\n",
        "    \n",
        "    # 2. Save the scaler\n",
        "    scaler_path = '../models/scaler.pkl'\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "    print(f\"‚úÖ Saved scaler: {scaler_path}\")\n",
        "    \n",
        "    # 3. Save the feature columns (order is important!)\n",
        "    columns_path = '../models/model_columns.pkl'\n",
        "    joblib.dump(list(X.columns), columns_path)\n",
        "    print(f\"‚úÖ Saved feature columns: {columns_path}\")\n",
        "    \n",
        "    print(f\"\\nüéØ DEPLOYMENT PACKAGE CREATED:\")\n",
        "    print(f\"  Model: {model_name}\")\n",
        "    print(f\"  Features: {len(X.columns)} columns\")\n",
        "    print(f\"  Performance: F1-Score = {comparison.iloc[best_model_idx]['F1-Score']:.4f}\" if 'best_model_idx' in locals() else \"\")\n",
        "    \n",
        "    # Test the saved model to ensure it works\n",
        "    print(f\"\\nüß™ TESTING SAVED MODEL:\")\n",
        "    try:\n",
        "        # Load the saved components\n",
        "        loaded_model = joblib.load(model_path)\n",
        "        loaded_scaler = joblib.load(scaler_path)\n",
        "        loaded_columns = joblib.load(columns_path)\n",
        "        \n",
        "        # Test with a sample\n",
        "        test_sample = X_test.iloc[0:1]\n",
        "        test_sample_scaled = loaded_scaler.transform(test_sample)\n",
        "        prediction = loaded_model.predict(test_sample_scaled)[0]\n",
        "        probability = loaded_model.predict_proba(test_sample_scaled)[0][1]\n",
        "        \n",
        "        print(f\"  ‚úÖ Model loading: SUCCESS\")\n",
        "        print(f\"  ‚úÖ Sample prediction: {prediction} (fraud probability: {probability:.3f})\")\n",
        "        print(f\"  ‚úÖ Feature order preserved: {len(loaded_columns)} columns\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ùå Error testing saved model: {e}\")\n",
        "    \n",
        "    print(f\"\\nüìù DEPLOYMENT INSTRUCTIONS:\")\n",
        "    print(f\"  1. Copy the 3 .pkl files to your FastAPI models/ directory\")\n",
        "    print(f\"  2. The API will automatically load these files on startup\")\n",
        "    print(f\"  3. Send transaction data to /predict/transaction endpoint\")\n",
        "    print(f\"  4. API will return fraud probability and risk level\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No model available for deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_inventory_section"
      },
      "source": [
        "## üìã **Model Inventory & File Summary**\n",
        "\n",
        "Let's create a comprehensive inventory of all saved models and their purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model_inventory"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive model inventory\n",
        "print(\"üìã MODEL INVENTORY - ALL SAVED FILES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import os\n",
        "models_dir = '../models'\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "print(\"\\nüéØ ALGORITHM-SPECIFIC TRAINING FILES:\")\n",
        "training_files = [\n",
        "    (\"logistic_regression_model.pkl\", \"Logistic Regression trained model\"),\n",
        "    (\"logistic_regression_scaler.pkl\", \"Scaler used for Logistic Regression\"),\n",
        "    (\"logistic_regression_columns.pkl\", \"Feature columns for Logistic Regression\"),\n",
        "    (\"random_forest_model.pkl\", \"Random Forest trained model\"),\n",
        "    (\"random_forest_scaler.pkl\", \"Scaler used for Random Forest\"),\n",
        "    (\"random_forest_columns.pkl\", \"Feature columns for Random Forest\"),\n",
        "    (\"random_forest_importance.pkl\", \"Feature importance scores from Random Forest\")\n",
        "]\n",
        "\n",
        "for filename, description in training_files:\n",
        "    filepath = os.path.join(models_dir, filename)\n",
        "    exists = \"‚úÖ\" if os.path.exists(filepath) else \"‚ùå\"\n",
        "    print(f\"  {exists} {filename:<35} - {description}\")\n",
        "\n",
        "print(\"\\nüöÄ PRODUCTION-READY FILES (for FastAPI):\")\n",
        "production_files = [\n",
        "    (\"fraud_model.pkl\", \"Best model selected for production deployment\"),\n",
        "    (\"scaler.pkl\", \"Scaler for production model preprocessing\"),\n",
        "    (\"model_columns.pkl\", \"Feature column order for production model\")\n",
        "]\n",
        "\n",
        "for filename, description in production_files:\n",
        "    filepath = os.path.join(models_dir, filename)\n",
        "    exists = \"‚úÖ\" if os.path.exists(filepath) else \"‚ùå\"\n",
        "    print(f\"  {exists} {filename:<35} - {description}\")\n",
        "\n",
        "# Save model metadata for future reference\n",
        "model_metadata = {\n",
        "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'dataset_shape': df.shape if 'df' in locals() else 'Unknown',\n",
        "    'algorithms_trained': [],\n",
        "    'best_model': None,\n",
        "    'performance_metrics': {}\n",
        "}\n",
        "\n",
        "# Add algorithm information\n",
        "if 'lr_model' in locals():\n",
        "    model_metadata['algorithms_trained'].append('Logistic Regression')\n",
        "    if 'test_f1' in locals():\n",
        "        model_metadata['performance_metrics']['Logistic Regression'] = {\n",
        "            'F1-Score': test_f1,\n",
        "            'Precision': test_precision,\n",
        "            'Recall': test_recall,\n",
        "            'AUC': test_auc\n",
        "        }\n",
        "\n",
        "if 'rf_model' in locals():\n",
        "    model_metadata['algorithms_trained'].append('Random Forest')\n",
        "    if 'test_f1_rf' in locals():\n",
        "        model_metadata['performance_metrics']['Random Forest'] = {\n",
        "            'F1-Score': test_f1_rf,\n",
        "            'Precision': test_precision_rf,\n",
        "            'Recall': test_recall_rf,\n",
        "            'AUC': test_auc_rf\n",
        "        }\n",
        "\n",
        "if 'best_model_name' in locals():\n",
        "    model_metadata['best_model'] = best_model_name\n",
        "\n",
        "# Save metadata\n",
        "joblib.dump(model_metadata, os.path.join(models_dir, 'training_metadata.pkl'))\n",
        "print(f\"\\nüìä TRAINING METADATA:\")\n",
        "print(f\"  ‚úÖ training_metadata.pkl - Training session information and metrics\")\n",
        "\n",
        "print(\"\\nüí° USAGE GUIDELINES:\")\n",
        "print(\"  üéØ For Production: Use fraud_model.pkl, scaler.pkl, model_columns.pkl\")\n",
        "print(\"  üî¨ For Research: Use algorithm-specific files for detailed analysis\")\n",
        "print(\"  üìä For Reporting: Use training_metadata.pkl for performance comparisons\")\n",
        "print(\"  üîÑ For Retraining: Reference all files to understand previous approaches\")\n",
        "\n",
        "print(\"\\nüóÇÔ∏è  RECOMMENDED FILE ORGANIZATION:\")\n",
        "print(\"  üìÅ models/\")\n",
        "print(\"    ‚îú‚îÄ‚îÄ üöÄ Production Files (fraud_model.pkl, scaler.pkl, model_columns.pkl)\")\n",
        "print(\"    ‚îú‚îÄ‚îÄ üìà Logistic Regression (logistic_regression_*.pkl)\")\n",
        "print(\"    ‚îú‚îÄ‚îÄ üå≤ Random Forest (random_forest_*.pkl)\")\n",
        "print(\"    ‚îî‚îÄ‚îÄ üìä Metadata (training_metadata.pkl)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "insights_section"
      },
      "source": [
        "## üí° **8. Key Insights & Recommendations**\n",
        "\n",
        "Let's summarize our findings and provide actionable insights for fraud detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "final_insights"
      },
      "outputs": [],
      "source": [
        "# Generate final insights and recommendations\n",
        "print(\"üí° FRAUD DETECTION INSIGHTS & RECOMMENDATIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"\\nüîç KEY FINDINGS:\")\n",
        "\n",
        "# Data insights\n",
        "if 'fraud_counts' in locals():\n",
        "    fraud_rate = fraud_counts[1] / fraud_counts.sum()\n",
        "    print(f\"  üìä Dataset: {len(df):,} transactions, {fraud_rate*100:.1f}% fraud rate\")\n",
        "\n",
        "# Model performance insights\n",
        "if 'comparison' in locals():\n",
        "    best_model = comparison.loc[comparison['F1-Score'].idxmax()]\n",
        "    print(f\"  üèÜ Best Model: {best_model['Model']} (F1-Score: {best_model['F1-Score']:.3f})\")\n",
        "    print(f\"  üéØ Fraud Detection Rate: {best_model['Recall']*100:.1f}% (Recall)\")\n",
        "    print(f\"  üõ°Ô∏è  Precision: {best_model['Precision']*100:.1f}% (Accuracy of fraud alerts)\")\n",
        "\n",
        "# Feature importance insights\n",
        "if 'rf_importance' in locals():\n",
        "    top_feature = rf_importance.iloc[0]\n",
        "    print(f\"  üî• Most Important Feature: {top_feature['feature']} ({top_feature['importance']:.3f})\")\n",
        "\n",
        "print(\"\\nüö® HIGH-RISK PATTERNS IDENTIFIED:\")\n",
        "if 'sorted_factors' in locals():\n",
        "    for factor, stats in sorted_factors[:3]:\n",
        "        if stats['risk_multiplier'] != float('inf'):\n",
        "            print(f\"  ‚Ä¢ {factor}: {stats['risk_multiplier']:.1f}x higher fraud risk\")\n",
        "\n",
        "print(\"\\nüìà BUSINESS RECOMMENDATIONS:\")\n",
        "print(\"  1. ü§ñ REAL-TIME MONITORING:\")\n",
        "print(\"     - Deploy model for real-time transaction scoring\")\n",
        "print(\"     - Set risk thresholds based on business tolerance\")\n",
        "print(\"     - Implement automated blocking for high-risk transactions\")\n",
        "\n",
        "print(\"\\n  2. üéØ RISK-BASED AUTHENTICATION:\")\n",
        "print(\"     - Require additional verification for suspicious patterns\")\n",
        "print(\"     - Implement step-up authentication for high-risk scenarios\")\n",
        "print(\"     - Consider transaction limits for new accounts\")\n",
        "\n",
        "print(\"\\n  3. üìä CONTINUOUS IMPROVEMENT:\")\n",
        "print(\"     - Retrain model monthly with new data\")\n",
        "print(\"     - Monitor model performance and drift\")\n",
        "print(\"     - Collect feedback on false positives/negatives\")\n",
        "\n",
        "print(\"\\n  4. üõ†Ô∏è OPERATIONAL INTEGRATION:\")\n",
        "print(\"     - Integrate with existing fraud investigation workflows\")\n",
        "print(\"     - Train fraud analysts on model outputs\")\n",
        "print(\"     - Establish escalation procedures for different risk levels\")\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  IMPORTANT CONSIDERATIONS:\")\n",
        "print(\"  ‚Ä¢ Balance fraud prevention with customer experience\")\n",
        "print(\"  ‚Ä¢ Regularly validate model performance on new data\")\n",
        "print(\"  ‚Ä¢ Ensure compliance with financial regulations\")\n",
        "print(\"  ‚Ä¢ Monitor for model bias and fairness issues\")\n",
        "print(\"  ‚Ä¢ Maintain audit trails for all fraud decisions\")\n",
        "\n",
        "print(\"\\nüöÄ NEXT STEPS:\")\n",
        "print(\"  1. Deploy saved model files to FastAPI application\")\n",
        "print(\"  2. Test API endpoints with sample transactions\")\n",
        "print(\"  3. Configure risk thresholds based on business needs\")\n",
        "print(\"  4. Set up monitoring and alerting systems\")\n",
        "print(\"  5. Train operations team on new fraud detection system\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚úÖ FRAUD DETECTION MODEL READY FOR PRODUCTION!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "---\n",
        "\n",
        "# üéâ **Congratulations!**\n",
        "\n",
        "You have successfully built a **complete fraud detection system** from start to finish! \n",
        "\n",
        "## üéØ **What You've Accomplished:**\n",
        "\n",
        "‚úÖ **Data Analysis**: Explored transaction patterns and identified fraud indicators  \n",
        "‚úÖ **Feature Engineering**: Created meaningful features from raw transaction data  \n",
        "‚úÖ **Model Training**: Built and compared multiple machine learning models  \n",
        "‚úÖ **Performance Evaluation**: Assessed models using appropriate metrics for fraud detection  \n",
        "‚úÖ **Deployment Preparation**: Saved model artifacts for production use  \n",
        "‚úÖ **Business Insights**: Generated actionable recommendations for fraud prevention  \n",
        "\n",
        "## üöÄ **Your Model is Now Ready For:**\n",
        "- **Real-time fraud detection** via FastAPI\n",
        "- **Batch transaction processing** \n",
        "- **Risk-based authentication systems**\n",
        "- **Fraud investigation workflows**\n",
        "\n",
        "---\n",
        "\n",
        "**üí¨ Questions or want to improve the model further?**  \n",
        "Consider exploring:\n",
        "- Advanced algorithms (XGBoost, Neural Networks)\n",
        "- Feature selection techniques\n",
        "- Hyperparameter tuning\n",
        "- Ensemble methods\n",
        "- Anomaly detection approaches\n",
        "\n",
        "**Happy Fraud Fighting! üõ°Ô∏è**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
